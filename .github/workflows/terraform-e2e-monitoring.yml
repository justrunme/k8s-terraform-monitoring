name: Terraform E2E Monitoring

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  monitoring:
    runs-on: ubuntu-latest
    timeout-minutes: 40

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Kind & Kubectl
        run: |
          curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.23.0/kind-linux-amd64
          chmod +x ./kind
          sudo mv ./kind /usr/local/bin/kind
          curl -LO "https://dl.k8s.io/release/v1.29.0/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl

      - name: Create Kind Cluster
        run: kind create cluster --wait 60s

      - name: Wait for Cluster DNS (CoreDNS)
        run: |
          kubectl rollout status deployment/coredns -n kube-system --timeout=90s

      # --- Важно! Создаем hostPath для PV, если нужно ---
      - name: Prepare hostPath for PV (Kind)
        run: |
          docker exec kind-control-plane mkdir -p /tmp/demo-data || true
          docker exec kind-control-plane chmod 777 /tmp/demo-data || true

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        run: terraform init -backend=false

      # === Шаг 1: Деплой только Helm-чарта kube-prometheus-stack ===
      - name: Deploy kube-prometheus-stack (Helm only)
        run: terraform apply -target=helm_release.kube_prometheus_stack -auto-approve

      # === Шаг 2: Ждем CRD ===
      - name: Wait for ServiceMonitor CRD
        run: |
          for i in {1..30}; do
            kubectl get crd servicemonitors.monitoring.coreos.com && exit 0
            echo "Waiting for CRD ServiceMonitor..."
            sleep 10
          done
          echo "CRD ServiceMonitor not found after timeout!" >&2
          exit 1

      # === Шаг 3: Apply весь остальной Terraform (app, ServiceMonitor и т.д.) ===
      - name: Terraform Apply (All resources)
        run: terraform apply -auto-approve

      # === Шаг 4: Проверки, что всё реально работает ===
      - name: Check Grafana NodePort
        run: |
          kubectl get svc -n monitoring | grep grafana
          kubectl get pods -n monitoring | grep grafana

      - name: Port-forward Grafana & check login page
        run: |
          kubectl port-forward svc/kube-prometheus-stack-grafana 30090:30090 -n monitoring &
          sleep 10
          curl -sf http://localhost:30090/login | grep "grafana" || (echo "No Grafana page" && exit 1)

      - name: Port-forward Prometheus & check status page
        run: |
          kubectl port-forward svc/kube-prometheus-stack-prometheus 30091:9090 -n monitoring &
          sleep 10
          curl -sf http://localhost:30091/ | grep "Prometheus" || (echo "No Prometheus page" && exit 1)

      - name: Check test-app available
        run: |
          kubectl port-forward svc/test-app 8000:80 -n monitoring &
          sleep 5
          curl -sf http://localhost:8000/ | grep "Welcome to nginx" || (echo "test-app not available" && exit 1)

      # === Шаг 5: Удаление ресурсов ===
      - name: Terraform Destroy
        if: always()
        run: terraform destroy -auto-approve

      - name: Delete Kind Cluster
        if: always()
        run: kind delete cluster
